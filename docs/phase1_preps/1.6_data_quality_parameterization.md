# Phase 1.6: data_quality.R Migration (Parameterization Plan)
**Target:** core/data_quality.R (universal) + domain/data_quality.R (COHA wrapper - optional)  
**Source:** R/functions/data_quality.R (415 lines, 3 functions)  
**Approach:** Option A - Parameterize compute_quality_metrics()  
**Complexity:** ‚≠ê‚≠ê‚≠ê Moderate  
**Estimated Time:** 2.5-3.5 hours  
**Risk Level:** üü° Medium (refactoring + thorough testing required)  
**Status:** Ready to Execute

---

## Prerequisites
- ‚úÖ Sub-Phase 0.1.4 audit complete (0.1.4_data_quality_audit.md)
- ‚úÖ Dependencies identified (assertions.R, logging.R, robustness.R)
- ‚úÖ All COHA hardcodes documented
- ‚úÖ Test data available (COHA dataset)

---

## Executive Summary

**Current State:**
```
R/functions/data_quality.R  (415 lines)
  - compute_quality_metrics()     [100 lines] - has COHA hardcodes
  - calculate_quality_score()     [100 lines] - 100% universal
  - generate_quality_report()     [60 lines]  - 100% universal
```

**Target State:**
```
core/data_quality.R  (420 lines - refactored)
  - compute_quality_metrics()     [120 lines] - PARAMETERIZED (universal)
  - calculate_quality_score()     [100 lines] - unchanged
  - generate_quality_report()     [60 lines]  - unchanged

domain_modules/coha_dispersal/data_quality.R  (optional, 30 lines)
  - compute_coha_quality_metrics() [30 lines] - convenience wrapper
```

**Change:** Refactor 1 function to use parameters (25 minutes) + comprehensive tests (60 minutes)

---

## File Analysis Summary

**File:** R/functions/data_quality.R  
**Lines:** 415  
**Functions:** 3

| Function | Type | Status | Action |
|----------|------|--------|--------|
| compute_quality_metrics | Core + COHA | üü° Refactor | Add parameters, keep logic |
| calculate_quality_score | 100% Core | ‚úÖ Keep | Move as-is |
| generate_quality_report | 100% Core | ‚úÖ Keep | Move as-is |

**Universal Elements:**
- Quality metric computation pattern (generic)
- Scoring algorithm (weights-based, generic)
- Report generation (template-like)

**COHA-Specific Elements (Lines to fix):**
- Line 85: `required_columns = c("mass", "year", "dispersed")` ‚Üê Default only
- Line 131: `if ("mass" %in% names(df))` ‚Üê Hardcoded check
- Line 134: `if ("year" %in% names(df))` ‚Üê Hardcoded check
- Line 137: `if ("dispersed" %in% names(df))` ‚Üê Hardcoded check
- Line 140: `/3` ‚Üê Hardcoded column count
- Line 169: `df$mass < 0 | df$mass > 1000` ‚Üê 0-1000g COHA range
- Line 175: `df$year < 1980 | df$year > 2027` ‚Üê COHA study period

**Dependencies:**
- External: dplyr, base R
- Internal: assertions.R, logging.R, robustness.R

---

## Implementation Plan

### Phase 1.6.1: Refactor compute_quality_metrics()

**Current Function Signature:**
```r
compute_quality_metrics <- function(df,
                                    required_columns = c("mass", "year", "dispersed"),
                                    min_rows = 10,
                                    verbose = FALSE)
```

**New Function Signature:**
```r
compute_quality_metrics <- function(df,
                                    required_columns = c("mass", "year", "dispersed"),
                                    column_types = NULL,
                                    outlier_ranges = NULL,
                                    min_rows = 10,
                                    verbose = FALSE)
```

**New Parameters:**

```r
#' @param column_types List. Expected types for each required column.
#'   Format: list(column_name = "numeric"|"character"|"logical", ...)
#'   Default: NULL (inferred from required_columns)
#'
#' @param outlier_ranges List. Valid ranges for numeric columns only.
#'   Format: list(column_name = c(min, max), ...)
#'   Default: NULL (no range checking)
#'   Example: list(mass = c(0, 1000), year = c(1980, 2027))
```

### Phase 1.6.2: Add Default Inference Logic

**Add this section after validation:**

```r
# Infer column types from column names if not provided
if (is.null(column_types)) {
  column_types <- list()
  for (col in required_columns) {
    # Heuristic: columns with standard names default to their common types
    if (col %in% c("dispersed", "origin", "location", "name", "category")) {
      column_types[[col]] <- "character"
    } else if (col %in% c("mass", "year", "weight", "height", "distance")) {
      column_types[[col]] <- "numeric"
    } else if (col %in% c("success", "is_valid", "completed", "active")) {
      column_types[[col]] <- "logical"
    } else {
      # Default to numeric for unknown columns
      column_types[[col]] <- "numeric"
    }
  }
}

# Set default outlier_ranges to NULL if not provided
# (range checking will be skipped for any columns without ranges)
if (is.null(outlier_ranges)) {
  outlier_ranges <- list()
}
```

### Phase 1.6.3: Refactor Schema Validation Loop

**OLD CODE (Hardcoded):**
```r
# Check mass column
if ("mass" %in% names(df) && is.numeric(df$mass)) {
  schema_correct <- schema_correct + 1
}
# Check year column  
if ("year" %in% names(df) && is.numeric(df$year)) {
  schema_correct <- schema_correct + 1
}
# Check dispersed column
if ("dispersed" %in% names(df) && is.character(df$dispersed)) {
  schema_correct <- schema_correct + 1
}

metrics$schema_match <- schema_correct / 3 * 100  # ‚Üê Hardcoded
```

**NEW CODE (Parameterized):**
```r
# Validate using required_columns and column_types
for (col in required_columns) {
  expected_type <- column_types[[col]]
  
  if (col %in% names(df)) {
    # Check type matches
    col_is_correct <- switch(expected_type,
      "numeric" = is.numeric(df[[col]]),
      "character" = is.character(df[[col]]),
      "logical" = is.logical(df[[col]]),
      FALSE  # Unknown type
    )
    
    if (col_is_correct) {
      schema_correct <- schema_correct + 1
    } else if (verbose) {
      warning(sprintf("Column '%s' expected %s but got %s",
                      col, expected_type, class(df[[col]])[1]))
    }
  }
}

# Use length of required_columns instead of hardcoded 3
metrics$schema_match <- schema_correct / length(required_columns) * 100
```

### Phase 1.6.4: Refactor Outlier Detection Loop

**OLD CODE (Hardcoded):**
```r
# Mass range
if ("mass" %in% names(df)) {
  mass_issues <- sum(df$mass < 0 | df$mass > 1000, na.rm = TRUE)
  metrics$outliers_detected <- metrics$outliers_detected + mass_issues
  if (mass_issues > 0) {
    metrics$warnings <- c(metrics$warnings,
                         sprintf("%d mass values outside 0-1000 range", mass_issues))
  }
}

# Year range
if ("year" %in% names(df)) {
  year_issues <- sum(df$year < 1980 | df$year > 2027, na.rm = TRUE)
  metrics$outliers_detected <- metrics$outliers_detected + year_issues
  if (year_issues > 0) {
    metrics$warnings <- c(metrics$warnings,
                         sprintf("%d year values outside 1980-2027 range", year_issues))
  }
}
```

**NEW CODE (Parameterized):**
```r
# Check outliers for all columns with defined ranges
for (col in names(outlier_ranges)) {
  if (col %in% names(df) && is.numeric(df[[col]])) {
    range <- outlier_ranges[[col]]
    
    # Check bounds
    issues <- sum(df[[col]] < range[1] | df[[col]] > range[2], na.rm = TRUE)
    metrics$outliers_detected <- metrics$outliers_detected + issues
    
    if (issues > 0) {
      metrics$warnings <- c(metrics$warnings,
        sprintf("%d '%s' values outside %d-%d range",
                issues, col, range[1], range[2]))
    }
  }
}
```

---

## Usage Examples

### Example 1: COHA Data (Default Behavior)

```r
# Method A: Use defaults (backward compatible)
coha_metrics <- compute_quality_metrics(
  coha_data,
  required_columns = c("mass", "year", "dispersed"),
  min_rows = 10
)
# Uses inferred types (mass/year = numeric, dispersed = character)
# No outlier checking by default

# Method B: Explicit with ranges (how to use in domain module)
coha_metrics <- compute_quality_metrics(
  coha_data,
  required_columns = c("mass", "year", "dispersed", "origin"),
  column_types = list(
    mass = "numeric",
    year = "numeric", 
    dispersed = "character",
    origin = "character"
  ),
  outlier_ranges = list(
    mass = c(0, 1000),      # Hawks: 200g-1000g typical
    year = c(1980, 2027)    # COHA study period
  ),
  min_rows = 10
)
```

### Example 2: Migration Study

```r
migration_metrics <- compute_quality_metrics(
  migration_data,
  required_columns = c("origin", "destination", "distance_km"),
  column_types = list(
    origin = "character",
    destination = "character",
    distance_km = "numeric"
  ),
  outlier_ranges = list(
    distance_km = c(0, 5000)  # Up to 5000km migration
  ),
  min_rows = 50
)
```

### Example 3: Temperature Model

```r
temp_metrics <- compute_quality_metrics(
  temperature_data,
  required_columns = c("temperature_celsius", "location", "date"),
  column_types = list(
    temperature_celsius = "numeric",
    location = "character",
    date = "character"
  ),
  outlier_ranges = list(
    temperature_celsius = c(-50, 50)  # Realistic Earth temperatures
  ),
  min_rows = 365  # At least a year of data
)
```

---

## Testing Plan

### Test 1: Backward Compatibility

```r
# Old code should still work exactly as before
old_result <- compute_quality_metrics(coha_data)

# New code with explicit COHA values
new_result <- compute_quality_metrics(
  coha_data,
  required_columns = c("mass", "year", "dispersed"),
  column_types = list(
    mass = "numeric",
    year = "numeric",
    dispersed = "character"
  ),
  outlier_ranges = list(
    mass = c(0, 1000),
    year = c(1980, 2027)
  )
)

# Results should be identical
testthat::expect_equal(old_result$completeness, new_result$completeness)
testthat::expect_equal(old_result$outliers_detected, new_result$outliers_detected)
```

### Test 2: Custom Columns

```r
# Create test data with different columns
custom_data <- data.frame(
  origin = c("A", "B", "C"),
  destination = c("D", "E", "F"),
  cost = c(100, 200, 300)
)

custom_metrics <- compute_quality_metrics(
  custom_data,
  required_columns = c("origin", "destination", "cost"),
  column_types = list(
    origin = "character",
    destination = "character",
    cost = "numeric"
  ),
  outlier_ranges = list(
    cost = c(0, 500)
  )
)

# Should pass validation
testthat::expect_equal(custom_metrics$schema_match, 100)  # All 3 columns correct
testthat::expect_equal(custom_metrics$outliers_detected, 0)  # All costs in range
```

### Test 3: Outlier Detection

```r
# Data with outliers
outlier_data <- data.frame(
  mass = c(100, 500, 2000),  # Last one is outlier (> 1000)
  year = c(1990, 2010, 1970),  # Last one is outlier (< 1980)
  dispersed = c("yes", "no", "yes")
)

outlier_metrics <- compute_quality_metrics(
  outlier_data,
  required_columns = c("mass", "year", "dispersed"),
  column_types = list(mass = "numeric", year = "numeric", dispersed = "character"),
  outlier_ranges = list(
    mass = c(0, 1000),
    year = c(1980, 2027)
  )
)

# Should detect 2 outliers
testthat::expect_equal(outlier_metrics$outliers_detected, 2)
testthat::expect_true(any(grepl("mass.*outside", outlier_metrics$warnings)))
testthat::expect_true(any(grepl("year.*outside", outlier_metrics$warnings)))
```

### Test 4: Type Inference

```r
# When type inference is used
inferred_metrics <- compute_quality_metrics(
  coha_data,
  required_columns = c("mass", "year", "dispersed")
  # column_types NOT provided - should infer
)

# Should still work
testthat::expect_true(!is.null(inferred_metrics$completeness))
testthat::expect_true(!is.na(inferred_metrics$quality_score))
```

---

## Optional: Create COHA Wrapper (Domain Module)

**File:** domain_modules/coha_dispersal/data_quality.R

```r
#' COHA-Specific Quality Metrics Wrapper
#'
#' @description
#' Convenience function that wraps compute_quality_metrics() with COHA-specific
#' defaults (column names, data types, outlier ranges).
#'
#' @param df Data frame. COHA dispersal dataset
#' @param min_rows Integer. Minimum acceptable row count. Default: 10
#' @param verbose Logical. Print details. Default: FALSE
#'
#' @return List with quality metrics (see compute_quality_metrics)
#'
#' @details
#' This is a thin wrapper around the universal compute_quality_metrics()
#' that pre-configures COHA-specific values:
#' - Required columns: mass, year, dispersed, origin
#' - Mass range: 0-1000g (typical hawk dispersal)
#' - Year range: 1980-2027 (COHA study period)
#'
#' @examples
#' \dontrun{
#' coha_metrics <- compute_coha_quality_metrics(bird_data)
#' }
#'
#' @export
compute_coha_quality_metrics <- function(df, min_rows = 10, verbose = FALSE) {
  
  # Import universal function
  # (will be sourced from core/data_quality.R after Phase 1)
  
  compute_quality_metrics(
    df,
    required_columns = c("mass", "year", "dispersed", "origin"),
    column_types = list(
      mass = "numeric",
      year = "numeric",
      dispersed = "character",
      origin = "character"
    ),
    outlier_ranges = list(
      mass = c(0, 1000),    # Grams - typical hawk masses
      year = c(1980, 2027)  # COHA study period
    ),
    min_rows = min_rows,
    verbose = verbose
  )
}
```

---

## Validation Checklist

**Code Refactoring:**
- [ ] New parameters added to function signature
- [ ] Type inference logic implemented
- [ ] Schema validation loop updated to use parameters
- [ ] Outlier detection loop updated to use parameters
- [ ] Documentation (roxygen) updated with new parameters
- [ ] All old hardcoded values removed

**Testing:**
- [ ] Backward compatibility test passes (old behavior preserved)
- [ ] Custom columns work with different schemas
- [ ] Outlier detection works with custom ranges
- [ ] Type inference works when column_types not provided
- [ ] Edge cases handled (empty ranges, missing columns, etc.)
- [ ] calculate_quality_score() works unchanged
- [ ] generate_quality_report() works unchanged
- [ ] All functions integrate with existing pipeline

**Integration:**
- [ ] calculate_quality_score() still callable
- [ ] generate_quality_report() still callable
- [ ] Dependencies (assertions.r, logging.R) still work
- [ ] No breaking changes to existing code
- [ ] COHA wrapper created (optional but recommended)

---

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Type inference wrong** | Medium | Low | Thorough unit tests, documentation |
| **Outlier detection edge case** | Low | Low | Handle empty ranges, NA values |
| **Performance degradation** | Low | Low | Use vectorized operations (already do) |
| **Breaking change** | Low | Medium | Extensive backward compatibility testing |

**Overall Risk Level:** üü° Medium (due to refactoring) ‚Üí üü¢ Low (if tests pass)

---

## Time Breakdown

| Task | Time |
|------|------|
| Code refactoring | 25 min |
| Writing unit tests | 40 min |
| Testing & debugging | 30 min |
| Documentation | 10 min |
| COHA wrapper (optional) | 15 min |
| **Total** | **2.5-3.5 hrs** |

---

## Git Workflow

```bash
# Create feature branch
git checkout -b phase/1.6-data-quality-parameterization

# Make changes to R/functions/data_quality.R
# Alternatively: Create core/data_quality.R with refactored version

# Test thoroughly
# ... run tests ...

# Stage changes
git add R/functions/data_quality.R
git add domain_modules/coha_dispersal/data_quality.R  # If creating wrapper

# Commit
git commit -m "Phase 1.6: Parameterize compute_quality_metrics() for universality"

# Merge to main after all testing
git checkout main
git merge phase/1.6-data-quality-parameterization
```

---

## Success Criteria

‚úÖ **Migration Complete When:**
1. compute_quality_metrics() refactored with 3 new parameters
2. All hardcoded COHA values replaced with parameter defaults
3. Schema validation loop uses parameters (not hardcoded columns)
4. Outlier checking loop uses parameters
5. Backward compatibility tests pass (old calls work unchanged)
6. New parameter usage works (custom schemas tested)
7. Type inference works correctly
8. COHA wrapper created (optional but recommended)
9. All tests pass (unit + integration)
10. Documentation updated

---

## Next Steps

After refactoring and testing:
1. ‚úÖ Move both calculate_quality_score() and generate_quality_report() to core/
2. ‚úÖ Move new parameterized compute_quality_metrics() to core/
3. ‚úÖ Create COHA wrapper in domain module (optional)
4. ‚úÖ Return to Phase 1.4-1.5 cleanup after all migrations

---

**Status:** Ready for Execution  
**Approach:** Option A (Parameterize) - Recommended  
**Effort:** 2.5-3.5 hours with thorough testing  
**Next:** Code refactoring ‚Üí Testing ‚Üí Verification

