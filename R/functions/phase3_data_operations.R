# ==============================================================================
# R/functions/phase3_data_operations.R
# ==============================================================================
# PURPOSE
# -------
# Phase 3 data operations with structured returns and quality reporting.
# All functions return result objects with status, message, quality metrics.
#
# DEPENDS ON
# ----------
# - R/functions/assertions.R (validation)
# - R/functions/logging.R (audit trail)
# - R/functions/robustness.R (result objects)
# - R/functions/data_quality.R (quality metrics)
# - R/functions/utilities.R (safe I/O)
# - readr, dplyr
#
# INPUTS
# ------
# File paths, configuration objects, data frames
#
# OUTPUTS
# -------
# Structured result objects with status, data, quality scores
#
# USAGE
# -----
# source(\"R/functions/phase3_data_operations.R\")\n# result <- load_and_validate_data(\"data/data.csv\", verbose = TRUE)\n# if (result$status == \"success\") { df <- result$data }\n#\n# CHANGELOG\n# ---------\n# 2026-02-10 (v1.0.0): Phase 3 - Initial data operations\n#   - load_and_validate_data() - Load CSV with quality assessment\n#   - assess_data_quality() - Full quality analysis of loaded data\n#\n# ==============================================================================\n\n#' Load and Validate Data with Quality Assessment\n#'\n#' @description\n#' Loads CSV file, validates schema, computes quality metrics.\n#' Returns structured result with status, data, and quality score.\n#' Unlike Phase 1 safe_read_csv(), this returns comprehensive quality info.\n#'\n#' @param file_path Character. Path to CSV file.\n#' @param required_columns Character vector. Expected columns.\n#'   Default: c(\"mass\", \"year\", \"dispersed\", \"origin\").\n#' @param min_rows Integer. Minimum acceptable row count. Default: 10.\n#' @param verbose Logical. Print progress messages. Default: FALSE.\n#'\n#' @return List. Structured result with fields:\n#'   - status: \"success\", \"partial\", or \"failed\"\n#'   - message: Human-readable status description\n#'   - data: Data frame if status != \"failed\"\n#'   - rows: Number of rows loaded\n#'   - columns: Number of columns\n#'   - quality_score: 0-100 quality assessment\n#'   - quality_metrics: Detailed quality breakdown\n#'   - errors: List of errors encountered\n#'   - warnings: List of warnings (non-blocking issues)\n#'   - timestamp: When operation completed\n#'   - duration_secs: How long operation took\n#'\n#' @details\n#' **Execution Steps:**\n#' 1. Validate input file path exists\n#' 2. Read CSV (returns NULL on read error)\n#' 3. Validate required columns exist\n#' 4. Compute quality metrics\n#' 5. Calculate overall quality score\n#' 6. Determine status based on quality\n#'    - 90+: success\n#'    - 50-89: partial (issues but usable)\n#'    - <50: failed (too many issues)\n#'\n#' **Quality Assessment:**\n#' - Completeness (30%): % of non-NA cells\n#' - Schema (30%): % of correct columns/types\n#' - Row count (20%): meets minimum threshold\n#' - Outliers (20%): count of suspicious values\n#'\n#' **Verbose Output:** Shows each validation step with ✓/✗ indicators.\n#'\n#' @examples\n#' \\dontrun{\n#' # Basic usage\n#' result <- load_and_validate_data(\n#'   here::here(\"data\", \"data.csv\"),\n#'   verbose = TRUE\n#' )\n#'\n#' # Check success\n#' if (result$status == \"success\") {\n#'   df <- result$data\n#'   message(sprintf(\"Loaded %d records\", result$rows))\n#' } else if (result$status == \"partial\") {\n#'   warning(sprintf(\"Quality score: %d, proceed with caution\",\n#'                  result$quality_score))\n#'   df <- result$data  # Still available\n#' } else {\n#'   stop(sprintf(\"Load failed: %s\", result$message))\n#' }\n#'\n#' # Examine quality details\n#' print(result$quality_metrics$warnings)\n#' }\n#'\n#' @seealso [safe_read_csv()] for Phase 1 version,\n#'   [calculate_quality_score()] for scoring details\n#'\n#' @export\nload_and_validate_data <- function(file_path,\n                                    required_columns = c(\n                                      \"mass\", \"year\",\n                                      \"dispersed\", \"origin\"\n                                    ),\n                                    min_rows = 10,\n                                    verbose = FALSE) {\n\n  # Initialize result\n  result <- create_result(\"load_and_validate_data\", verbose)\n  start_time <- start_timer()\n\n  if (verbose) {\n    message(sprintf(\"[DATA] Loading from: %s\", file_path))\n  }\n\n  # 1. Validate file exists\n  tryCatch(\n    {\n      assert_file_exists(file_path, \"data file\")\n    },\n    error = function(e) {\n      result <<- add_error(\n        result,\n        format_error_message(\n          \"load_data\",\n          sprintf(\"File not found: %s\", basename(file_path)),\n          sprintf(\"Check YAML config - ensure %s exists\", basename(file_path))\n        ),\n        verbose\n      )\n    }\n  )\n\n  if (result$status == \"failed\") {\n    result$duration_secs <- stop_timer(start_time)\n    return(invisible(result))\n  }\n\n  # 2. Read CSV\n  if (verbose) message(\"[DATA] Reading CSV...\")\n\n  df <- safe_read_csv(file_path, verbose = FALSE)\n\n  if (is.null(df)) {\n    result <- add_error(\n      result,\n      format_error_message(\n        \"load_data\",\n        sprintf(\"Failed to read CSV: %s\", basename(file_path)),\n        \"Check file format - must be valid CSV. See logs/error_log.txt.\"\n      ),\n      verbose\n    )\n    result$duration_secs <- stop_timer(start_time)\n    return(invisible(result))\n  }\n\n  if (verbose) {\n    message(sprintf(\"[DATA] ✓ Read %d rows, %d columns\",\n                   nrow(df), ncol(df)))\n  }\n\n  # 3. Validate required columns\n  tryCatch(\n    {\n      assert_columns_exist(df, required_columns, \"ridgeline data\")\n      if (verbose) message(\"[DATA] ✓ All required columns present\")\n    },\n    error = function(e) {\n      result <<- add_error(\n        result,\n        format_error_message(\n          \"load_data\",\n          sprintf(\"Missing columns: %s\", e$message),\n          sprintf(\n            \"CSV must contain: %s\",\n            paste(required_columns, collapse = \", \")\n          )\n        ),\n        verbose\n      )\n    }\n  )\n\n  if (result$status == \"failed\") {\n    result$duration_secs <- stop_timer(start_time)\n    return(invisible(result))\n  }\n\n  # 4. Compute quality metrics\n  if (verbose) message(\"[DATA] Assessing data quality...\")\n\n  metrics <- compute_quality_metrics(df, required_columns, min_rows, verbose)\n\n  # 5. Calculate quality score\n  quality_score <- calculate_quality_score(metrics)\n\n  if (verbose) {\n    message(sprintf(\"[DATA] Quality score: %.0f/100\", quality_score))\n  }\n\n  # 6. Set status based on quality\n  if (quality_score >= 90) {\n    result <- set_result_status(\n      result,\n      \"success\",\n      sprintf(\"Data loaded successfully (quality: %.0f/100)\", quality_score),\n      verbose\n    )\n  } else if (quality_score >= 50) {\n    result <- set_result_status(\n      result,\n      \"partial\",\n      sprintf(\"Data loaded with warnings (quality: %.0f/100)\", quality_score),\n      verbose\n    )\n    # Add warnings from metrics\n    for (warn in metrics$warnings) {\n      result <- add_warning(result, warn, verbose)\n    }\n  } else {\n    result <- add_error(\n      result,\n      format_error_message(\n        \"load_data\",\n        sprintf(\"Data quality too low (%.0f/100)\", quality_score),\n        sprintf(\n          \"Data has significant issues: %s. Consider data cleaning.\",\n          paste(metrics$warnings[1:min(2, length(metrics$warnings))], collapse=\"; \")\n        )\n      ),\n      verbose\n    )\n  }\n\n  # 7. Add data and metrics to result\n  result$data <- df\n  result$rows <- nrow(df)\n  result$columns <- ncol(df)\n  result$quality_score <- quality_score\n  result$quality_metrics <- metrics\n\n  # 8. Finalize\n  result$duration_secs <- stop_timer(start_time)\n  result$timestamp <- Sys.time()\n\n  if (verbose) {\n    message(sprintf(\"[DATA] Load complete (%.2f seconds)\", result$duration_secs))\n  }\n\n  invisible(result)\n}\n\n#' Assess Loaded Data Quality\n#'\n#' @description\n#' Full quality assessment of already-loaded data.\n#' Returns structured result with quality score and detailed report.\n#'\n#' @param df Data frame. Data to assess.\n#' @param required_columns Character vector. Expected columns.\n#'   Default: c(\"mass\", \"year\", \"dispersed\", \"origin\").\n#' @param min_rows Integer. Minimum acceptable row count. Default: 10.\n#' @param verbose Logical. Print detailed report. Default: TRUE.\n#'\n#' @return List. Structured result with:\n#'   - status: Always \"success\" (assessment always completes)\n#'   - quality_score: 0-100 overall score\n#'   - quality_metrics: Detailed breakdown by component\n#'   - interpretation: Text description of score\n#'   - report: Full quality report text\n#'\n#' @details\n#' Similar to load_and_validate_data() but operates on loaded data.\n#' Useful for checking quality of transformed data mid-pipeline.\n#'\n#' @examples\n#' \\dontrun{\n#' # After data transformation\n#' df_filtered <- df %>% filter(year > 2000)\n#'\n#' # Check quality of filtered data\n#' quality <- assess_data_quality(df_filtered, verbose = TRUE)\n#' if (quality$quality_score < 50) {\n#'   warning(quality$interpretation)\n#' }\n#' }\n#'\n#' @export\nassess_data_quality <- function(df,\n                                 required_columns = c(\n                                   \"mass\", \"year\",\n                                   \"dispersed\", \"origin\"\n                                 ),\n                                 min_rows = 10,\n                                 verbose = TRUE) {\n\n  result <- create_result(\"assess_data_quality\")\n  start_time <- start_timer()\n\n  # Validate input\n  tryCatch(\n    {\n      assert_data_frame(df, \"data frame\")\n    },\n    error = function(e) {\n      result$status <<- \"failed\"\n      result$message <<- e$message\n      result$errors <<- list(e$message)\n      return(result)\n    }\n  )\n\n  # Compute metrics\n  metrics <- compute_quality_metrics(df, required_columns, min_rows, verbose)\n  quality_score <- calculate_quality_score(metrics)\n\n  # Interpretation\n  interpretation <- if (quality_score >= 90) {\n    \"Excellent data quality, ready for analysis\"\n  } else if (quality_score >= 75) {\n    \"Good quality with minor issues\"\n  } else if (quality_score >= 50) {\n    \"Acceptable but has quality concerns\"\n  } else {\n    \"Poor quality, not recommended\"\n  }\n\n  # Generate report\n  report <- generate_quality_report(metrics, quality_score, verbose = !verbose)\n\n  # Finalize result\n  result$status <- \"success\"\n  result$message <- sprintf(\"Quality assessment complete (score: %.0f/100)\",\n                           quality_score)\n  result$quality_score <- quality_score\n  result$quality_metrics <- metrics\n  result$interpretation <- interpretation\n  result$report <- report\n  result$duration_secs <- stop_timer(start_time)\n  result$timestamp <- Sys.time()\n\n  if (verbose) {\n    message(report)\n  }\n\n  invisible(result)\n}\n\n# ==============================================================================\n# END R/functions/phase3_data_operations.R\n# ==============================================================================\n